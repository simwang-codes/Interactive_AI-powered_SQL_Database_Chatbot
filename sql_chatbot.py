from langchain_community.utilities import SQLDatabase
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
import sqlite3
import pandas as pd
import os
import re

load_dotenv()

db_path = "test.db" 
sqlite_uri = f"sqlite:///{db_path}"
db = SQLDatabase.from_uri(sqlite_uri)

def get_schema(_):
    return db.get_table_info()

sql_template = """
Based on the table schema below, write a SQL query that would answer the user's question:
{schema}

Question: {question}
SQL Query:
"""

prompt_sql = ChatPromptTemplate.from_template(sql_template)

llm = ChatOpenAI(model="gpt-4", temperature=0)

sql_chain = (
    RunnablePassthrough.assign(schema=get_schema)
    | prompt_sql
    | llm.bind(stop=["\nSQLResult:"])
    | StrOutputParser()
)

# Although StrOutputParser() will help use extract raw sql from llm, 
# if the question has error or not clear enough, gpt might still respond with extra metadata
# so to be 100% sure we only get raw sql commands from gpt, we use re here to extract raw sql command again
def extract_sql_from_response(response: str) -> str:
    match = re.search(r"(SELECT|WITH|INSERT|UPDATE|DELETE)[\s\S]+?;", response, re.IGNORECASE)
    return match.group(0).strip() if match else response.strip()

def run_query(query):
    return db.run(query)

response_template = """
Based on the table schema below, question, sql query, and sql response, write a natural language response:
{schema}

Question: {question}
SQL Query: {query}
SQL Response: {response}
"""

prompt_response = ChatPromptTemplate.from_template(response_template)

full_chain = (
    RunnablePassthrough.assign(query=sql_chain).assign(
        schema=get_schema,
        response=lambda vars: run_query(vars["query"])
    )
    | prompt_response
    | llm
)

if __name__ == "__main__":
    user_question = input("Ask a question about the database: ")

    # The .invoke will activate sql_chain, and push user_question into the prompt in the sql_chain
    raw_sql = sql_chain.invoke({"question": user_question})
    sql_query = extract_sql_from_response(raw_sql)

    print("\nüß† SQL Query Generated by LLM:\n", sql_query)

    # I connected with sqlite and run the generated query,
    # because I want the program to print the raw table for me
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        cursor.execute(sql_query)
        column_names = [desc[0] for desc in cursor.description]
        data = cursor.fetchall()
        conn.close()

        # Reconstruct table from results
        df = pd.DataFrame(data, columns=column_names)
        print("\nüìä Raw Query Result from Database:\n")
        print(df.to_markdown(index=False))
    except Exception as e:
        print("\n‚ùå Error executing query:", e)
        print("Raw result:\n", run_query(sql_query))

    # In the end I activated the full_chain to get a natural language answer from GPT
    # this step is connected with sql_chain section, and its seperated from sqlite interaction above
    final_answer = full_chain.invoke({"question": user_question})
    print("\nüí¨ Natural Language Answer:\n", final_answer.content)

# Below is the official guidlines of how to build chains using LangChain
# https://python.langchain.com/docs/how_to/sequence/

# Below is the workflow guideline of how to build interactive sql chatbot:
# https://alejandro-ao.com/chat-with-mysql-using-python-and-langchain/#create-the-langchain-chain
